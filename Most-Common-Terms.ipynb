{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load joined dataframe\n",
    "df = pd.read_csv('csv/metadata_text_merged.csv')\n",
    "# Remove rows with empty text column for now\n",
    "df = df.dropna(subset=['text'])\n",
    "# Filter out Barbados texts for this analysis\n",
    "df = df[df['Place Sent From'] != 'Barbados']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Aliases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "alias_df = pd.DataFrame()\n",
    "\n",
    "for alias_file in os.listdir('aliases/'):\n",
    "    temp = pd.read_csv('aliases/' + alias_file, header=None)\n",
    "    # Append to alias_df\n",
    "    alias_df = alias_df.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regex for alphabetical characters\n",
    "alpha_regex = re.compile('[^a-zA-Z\\s]')\n",
    "\n",
    "# Dict mapping alias to name\n",
    "alias_to_name = {}\n",
    "\n",
    "for _, row in alias_df.iterrows():\n",
    "    name = alpha_regex.sub('', row[0].strip().lower())\n",
    "\n",
    "    if row[1] is not np.nan and row[1] != '':\n",
    "        aliases = [alpha_regex.sub('', s.strip().lower()) for s in row[1].split(';')]\n",
    "    \n",
    "    for alias in aliases:\n",
    "        if alias != '':\n",
    "            alias_to_name[alias] = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort aliases in decreasing order by length so that longer phrases are replaced first\n",
    "aliases = alias_to_name.keys()\n",
    "aliases.sort(key=len, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def replace_aliases(text, alias_to_name, aliases):\n",
    "    for alias in aliases:\n",
    "        if alias in text:\n",
    "            text = text.replace(alias, alias_to_name[alias])\n",
    "    \n",
    "    return text\n",
    "\n",
    "def replace_double_letters(text):\n",
    "    '''Replace ff at beginning of word with f; tt and pp at end with single t and p'''\n",
    "    text_split = text.split(' ')\n",
    "    \n",
    "    for i, word in enumerate(text_split):\n",
    "        if word.startswith('ff'):\n",
    "            text_split[i] = text_split[i][1:]\n",
    "        if word.endswith('tt'):\n",
    "            text_split[i] = text_split[i][:-1]\n",
    "        if word.endswith('pp'):\n",
    "            text_split[i] = text_split[i][:-1]\n",
    "    \n",
    "    return ' '.join(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercasing\n",
    "df['text_cleaned'] = df['text'].apply((lambda x: \" \".join(x.lower() for x in x.split())))\n",
    "# remove punctuation\n",
    "df['text_cleaned'] = df['text_cleaned'].str.replace('[^\\w\\s]','')\n",
    "# stopword removal\n",
    "stop = stopwords.words('english')\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
    "# Replace all aliases with the term they actually refer to \n",
    "df['text_cleaned_dealiased'] = df['text_cleaned'].apply(lambda x: replace_aliases(x, alias_to_name, aliases))\n",
    "# Remove double letter occurrences\n",
    "df['text_cleaned_dealiased'] = df['text_cleaned_dealiased'].apply(lambda x: replace_double_letters(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of words that appear most frequently\n",
    "freq = pd.Series(' '.join(df['text_cleaned']).split()).value_counts()\n",
    "dealiased_freq = pd.Series(' '.join(df['text_cleaned_dealiased']).split()).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17478 16587\n"
     ]
    }
   ],
   "source": [
    "print len(freq), len(dealiased_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "send            2729\n",
       "sent            2598\n",
       "shall           2590\n",
       "mr              2400\n",
       "one             2390\n",
       "would           1932\n",
       "received        1875\n",
       "two             1839\n",
       "goods           1747\n",
       "slaves          1709\n",
       "per             1665\n",
       "desire          1650\n",
       "canoe           1624\n",
       "captain         1620\n",
       "may             1577\n",
       "soe             1343\n",
       "last            1244\n",
       "come            1223\n",
       "wee             1215\n",
       "great           1215\n",
       "worship         1206\n",
       "company         1137\n",
       "order           1119\n",
       "much            1113\n",
       "men             1111\n",
       "doe             1107\n",
       "good            1071\n",
       "att             1046\n",
       "give            1019\n",
       "came            1008\n",
       "people          1006\n",
       "time            1000\n",
       "corne            941\n",
       "pleased          922\n",
       "accompt          912\n",
       "royall           912\n",
       "itt              909\n",
       "hope             899\n",
       "dutch            898\n",
       "noe              885\n",
       "downe            882\n",
       "hand             877\n",
       "instant          871\n",
       "also             865\n",
       "hee              857\n",
       "hath             853\n",
       "mee              838\n",
       "since            800\n",
       "us               793\n",
       "want             788\n",
       "place            782\n",
       "upon             780\n",
       "take             771\n",
       "could            758\n",
       "account          735\n",
       "haveing          734\n",
       "trade            719\n",
       "make             718\n",
       "2                713\n",
       "ps               712\n",
       "day              711\n",
       "know             705\n",
       "man              698\n",
       "please           693\n",
       "goe              684\n",
       "three            682\n",
       "gold             671\n",
       "pray             655\n",
       "according        645\n",
       "honour           624\n",
       "3                617\n",
       "chests           612\n",
       "cabo             608\n",
       "gett             606\n",
       "sheets           599\n",
       "made             598\n",
       "well             598\n",
       "powder           597\n",
       "first            579\n",
       "night            576\n",
       "little           569\n",
       "comes            560\n",
       "factory          559\n",
       "worships         559\n",
       "john             557\n",
       "iron             549\n",
       "orders           544\n",
       "hundred          535\n",
       "fort             526\n",
       "morning          524\n",
       "present          514\n",
       "must             514\n",
       "letter           512\n",
       "reason           511\n",
       "cannot           510\n",
       "small            507\n",
       "accompts         506\n",
       "board            488\n",
       "perpetuanoes     487\n",
       "taken            487\n",
       "dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "send         2729\n",
       "sent         2605\n",
       "shall        2590\n",
       "mr           2400\n",
       "one          2390\n",
       "would        1932\n",
       "received     1876\n",
       "two          1839\n",
       "canoe        1758\n",
       "goods        1747\n",
       "slaves       1709\n",
       "per          1665\n",
       "desire       1650\n",
       "captain      1626\n",
       "may          1577\n",
       "so           1343\n",
       "worship      1292\n",
       "corn         1281\n",
       "last         1244\n",
       "great        1238\n",
       "come         1223\n",
       "wee          1215\n",
       "also         1187\n",
       "company      1151\n",
       "order        1119\n",
       "much         1113\n",
       "men          1111\n",
       "do           1107\n",
       "time         1073\n",
       "good         1071\n",
       "at           1046\n",
       "give         1019\n",
       "came         1008\n",
       "people       1006\n",
       "coast         975\n",
       "cape          955\n",
       "royal         954\n",
       "worships      951\n",
       "dutch         928\n",
       "pleased       922\n",
       "accompt       912\n",
       "it            909\n",
       "hope          899\n",
       "noe           885\n",
       "down          882\n",
       "hand          877\n",
       "instant       871\n",
       "castle        857\n",
       "hee           857\n",
       "hath          853\n",
       "mee           838\n",
       "since         800\n",
       "us            793\n",
       "want          790\n",
       "place         782\n",
       "upon          780\n",
       "take          771\n",
       "could         758\n",
       "account       735\n",
       "haveing       734\n",
       "three         721\n",
       "trade         719\n",
       "make          718\n",
       "2             713\n",
       "ps            712\n",
       "day           711\n",
       "know          705\n",
       "man           698\n",
       "please        693\n",
       "ship          684\n",
       "fort          684\n",
       "goe           684\n",
       "get           672\n",
       "gold          671\n",
       "pintados      659\n",
       "money         658\n",
       "pray          655\n",
       "sheets        646\n",
       "according     645\n",
       "honour        624\n",
       "factory       621\n",
       "3             617\n",
       "chests        612\n",
       "made          598\n",
       "well          598\n",
       "powder        597\n",
       "first         589\n",
       "says          584\n",
       "night         576\n",
       "put           574\n",
       "little        570\n",
       "comes         560\n",
       "john          557\n",
       "let           555\n",
       "iron          550\n",
       "cannot        545\n",
       "orders        544\n",
       "hundred       535\n",
       "yet           532\n",
       "morning       524\n",
       "dtype: int64"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dealiased_freq[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
