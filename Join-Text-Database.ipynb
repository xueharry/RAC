{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load cleaned text and metadata datasets\n",
    "text_df = pd.read_csv('csv/segmented_cleaned.csv')\n",
    "meta_df = pd.read_excel('csv/032818_RAC_Networks_Database.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Volume and Letter Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_vol(filename):\n",
    "    '''Extract Vol for each text'''\n",
    "    if 'Volume_III' in filename:\n",
    "        return 3\n",
    "    elif 'Vol_II'in filename:\n",
    "        return 2\n",
    "    elif 'Vol_1' or 'Vol_I'in filename:\n",
    "        return 1\n",
    "    elif 'Winneba_p150_152' in filename:\n",
    "        return 1\n",
    "    elif 'Tantumkweri_Quansas_Croome' in filename:\n",
    "        return 3\n",
    "    else:\n",
    "        # Sanity check for whether anything was missed\n",
    "        return None\n",
    "\n",
    "def extract_letter_number(section_title):\n",
    "    '''Extract letter number from section title'''\n",
    "    return section_title.split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "assert(sum(text_df['filename'].apply(extract_vol).isnull() == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add columns for Vol and LetterNo \n",
    "text_df['Vol'] = text_df['filename'].apply(extract_vol)\n",
    "text_df['LetterNo'] = text_df['section_title'].apply(extract_letter_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_df.to_csv('csv/segmented_with_numbers.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join with Metadata dataframe on Volume and Letter Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read cleaned dataframes\n",
    "text_df = pd.read_csv('csv/segmented_with_numbers.csv')\n",
    "meta_df = pd.read_excel('csv/032818_RAC_Networks_Database.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Join dataframes on Letter Number and Volume\n",
    "merged_df = pd.merge(meta_df, text_df, on=['Vol', 'LetterNo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter out for a subset of the columns\n",
    "merged_filtered = merged_df[[u'UID', u'Vol', u'LetterNo', u'Sender',  u'Place Sent From', u'Ship Name', u'Place Going To', u'Date',\n",
    "          u'Boat/Fort', u'RAC/Other Nation', u'text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_non_ascii(text):\n",
    "    '''Remove non-ASCII characters (mostly due to OCR parsing error)'''\n",
    "    if text is not np.nan:\n",
    "        return ''.join(i for i in text if ord(i)<128)\n",
    "    else:\n",
    "        return np.nan\n",
    "    \n",
    "# Strip away non-ASCII characters from columns\n",
    "for col in merged_filtered.columns:\n",
    "    if merged_filtered[col].dtype == np.object and col != 'Date':\n",
    "        merged_filtered[col] = merged_filtered[col].apply(remove_non_ascii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export joined dataframe to csv file\n",
    "merged_filtered.to_csv('csv/metadata_text_merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
